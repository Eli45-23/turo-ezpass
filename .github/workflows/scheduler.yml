name: Nightly Scraper Schedule

permissions:
  id-token: write
  contents: read

on:
  schedule:
    # Run nightly at 2 AM ET (6 AM UTC during standard time, 5 AM UTC during daylight time)
    # This uses 6 AM UTC for consistency - adjust as needed for daylight saving time
    - cron: '0 6 * * *'
  workflow_dispatch:  # Allow manual triggering

env:
  AWS_REGION: us-east-1
  AWS_ACCOUNT_ID: 486365525776
  
jobs:
  run-scraper:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      id-token: write
      contents: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/turo-ezpass-github-actions-role
          role-session-name: GitHubActions-Scheduler
          aws-region: ${{ env.AWS_REGION }}
          
      - name: Trigger scraper via EventBridge
        id: trigger
        run: |
          echo "Triggering scraper via EventBridge at $(date)"
          
          # Send event to trigger the ECS task
          aws events put-events --entries '[{
            "Source": "github.scheduler",
            "DetailType": "Scraper Trigger",
            "Detail": "{\"trigger\": \"scheduled\", \"run_id\": \"${{ github.run_id }}\", \"run_number\": \"${{ github.run_number }}\"}"
          }]'
          
          echo "âœ… Scraper trigger sent successfully"
          
      - name: Wait for scraper completion
        id: wait
        run: |
          echo "Waiting for scraper task to complete..."
          
          # Poll ECS for task status (adjust task definition name as needed)
          TASK_FAMILY="turo-ezpass-scraper"
          MAX_WAIT_TIME=1800  # 30 minutes
          POLL_INTERVAL=30    # 30 seconds
          ELAPSED=0
          
          while [ $ELAPSED -lt $MAX_WAIT_TIME ]; do
            # Get the latest task ARN
            TASK_ARN=$(aws ecs list-tasks --cluster default --family $TASK_FAMILY --desired-status RUNNING --query 'taskArns[0]' --output text)
            
            if [ "$TASK_ARN" != "None" ] && [ -n "$TASK_ARN" ]; then
              echo "Task running: $TASK_ARN"
              
              # Check task status
              TASK_STATUS=$(aws ecs describe-tasks --cluster default --tasks $TASK_ARN --query 'tasks[0].lastStatus' --output text)
              
              if [ "$TASK_STATUS" = "STOPPED" ]; then
                EXIT_CODE=$(aws ecs describe-tasks --cluster default --tasks $TASK_ARN --query 'tasks[0].containers[0].exitCode' --output text)
                if [ "$EXIT_CODE" = "0" ]; then
                  echo "âœ… Scraper completed successfully"
                  exit 0
                else
                  echo "âŒ Scraper failed with exit code: $EXIT_CODE"
                  exit 1
                fi
              fi
            else
              echo "No running task found, checking for recently stopped tasks..."
              
              # Check for recently stopped tasks
              STOPPED_TASK=$(aws ecs list-tasks --cluster default --family $TASK_FAMILY --desired-status STOPPED --query 'taskArns[0]' --output text)
              
              if [ "$STOPPED_TASK" != "None" ] && [ -n "$STOPPED_TASK" ]; then
                EXIT_CODE=$(aws ecs describe-tasks --cluster default --tasks $STOPPED_TASK --query 'tasks[0].containers[0].exitCode' --output text)
                STOPPED_AT=$(aws ecs describe-tasks --cluster default --tasks $STOPPED_TASK --query 'tasks[0].stoppedAt' --output text)
                
                # Check if task stopped recently (within last 5 minutes)
                CURRENT_TIME=$(date +%s)
                STOPPED_TIME=$(date -d "$STOPPED_AT" +%s 2>/dev/null || date -j -f "%Y-%m-%dT%H:%M:%S" "$STOPPED_AT" +%s 2>/dev/null || echo 0)
                TIME_DIFF=$((CURRENT_TIME - STOPPED_TIME))
                
                if [ $TIME_DIFF -lt 300 ]; then
                  if [ "$EXIT_CODE" = "0" ]; then
                    echo "âœ… Scraper completed successfully"
                    exit 0
                  else
                    echo "âŒ Scraper failed with exit code: $EXIT_CODE"
                    exit 1
                  fi
                fi
              fi
            fi
            
            sleep $POLL_INTERVAL
            ELAPSED=$((ELAPSED + POLL_INTERVAL))
            echo "Waiting... ($ELAPSED seconds elapsed)"
          done
          
          echo "âŒ Timeout waiting for scraper to complete"
          exit 1
          
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const issue = {
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸš¨ Scraper Failed - ${new Date().toISOString().split('T')[0]}`,
              body: `
              ## Scraper Failure Alert
              
              **Run ID:** ${{ github.run_id }}
              **Run Number:** ${{ github.run_number }}
              **Timestamp:** ${new Date().toISOString()}
              **Workflow:** ${{ github.workflow }}
              
              ### Details
              The nightly scraper ECS task has failed or timed out. Please check the ECS logs and CloudWatch.
              
              ### Action Items
              - [ ] Review the workflow logs: [View Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
              - [ ] Check ECS task logs in CloudWatch
              - [ ] Review any error screenshots in S3
              - [ ] Investigate login field changes or timeouts
              - [ ] Update selectors if needed
              
              ### Quick Links
              - [ECS Console](https://console.aws.amazon.com/ecs/home?region=${{ env.AWS_REGION }}#/clusters/default/tasks)
              - [CloudWatch Logs](https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#logsV2:log-groups)
              
              ---
              *This issue was automatically created by the GitHub Actions workflow.*
              `,
              labels: ['bug', 'scraper-failure', 'automated']
            };
            
            // Check if there's already an open issue for today
            const today = new Date().toISOString().split('T')[0];
            const existingIssues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'scraper-failure',
              per_page: 5
            });
            
            const todayIssue = existingIssues.data.find(issue => 
              issue.title.includes(today)
            );
            
            if (!todayIssue) {
              await github.rest.issues.create(issue);
              console.log('Created new failure issue');
            } else {
              console.log('Issue already exists for today:', todayIssue.html_url);
              // Add a comment to the existing issue
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: todayIssue.number,
                body: `Another failure occurred at ${new Date().toISOString()}. [View Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`
              });
            }
            
      - name: Report success
        if: success()
        run: |
          echo "âœ… Scraper ECS task completed successfully"
          echo "ğŸ“Š Results should be available in S3/CloudWatch"
          echo "ğŸ• Completed at: $(date)"